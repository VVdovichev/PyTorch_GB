{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+xkZM1wUIyPDt71p5kUtZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VVdovichev/PyTorch_GB/blob/main/HW_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Будем практиковаться на датасете недвижимости (sklearn.datasets.fetch_california_housing)\n",
        "\n",
        "Ваша задача:\n",
        "\n",
        "Создать Dataset для загрузки данных\n",
        "\n",
        "Обернуть его в Dataloader\n",
        "\n",
        "Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
        "\n",
        "Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели\n",
        "\n",
        "train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25"
      ],
      "metadata": {
        "id": "vLz0-CrZcbbu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "ai23R--ecMlO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "from torch.optim import SGD, RMSprop, Adam\n",
        "\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = fetch_california_housing(return_X_y=True)\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zgnw0RTclTM",
        "outputId": "9c7a7d65-76c1-416c-cb2a-14dcf2ac0dea"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20640, 8), (20640,))"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=25, random_state=13)\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0hIxmpZehWE",
        "outputId": "d6a7449e-6202-4703-a9a6-5506eaf0d6dc"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20615, 8), (25, 8), (20615,), (25,))"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y=None, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if self.transform is not None and self.y is not None:\n",
        "            return self.transform(self.X[index]), self.y[index]\n",
        "        elif self.transform is not None and self.y is None:\n",
        "            return self.transform(self.X[index])\n",
        "        elif self.transform is None and self.y is not None:\n",
        "            return self.X[index], self.y[index]\n",
        "        elif self.transform is None and self.y is None:\n",
        "            return self.X[index]\n",
        "    "
      ],
      "metadata": {
        "id": "1gTKvscWfB7Z"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MyData(x_train, y_train)\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True)"
      ],
      "metadata": {
        "id": "AATwHRZ3g8rz"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = MyData(x_test, y_test)\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True)"
      ],
      "metadata": {
        "id": "Pa9klK2chSGn"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(in_features=input_dim, out_features=input_dim*4)\n",
        "        self.ac_1 = nn.LeakyReLU(negative_slope=0.1)\n",
        "        self.bn_1 = nn.BatchNorm1d(num_features=input_dim*4)\n",
        "        self.do_1 = nn.Dropout(0.25)\n",
        "        self.fc_2 = nn.Linear(in_features=input_dim*4, out_features=input_dim*2)\n",
        "        self.ac_2 = nn.LeakyReLU()\n",
        "        self.bn_2 = nn.BatchNorm1d(num_features=input_dim*2)\n",
        "        self.do_2 = nn.Dropout(0.25)\n",
        "        self.fc_3 = nn.Linear(in_features=input_dim*2, out_features=1)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc_1(x)\n",
        "        x = self.ac_1(x)\n",
        "        x = self.bn_1(x)\n",
        "        x = self.do_1(x)\n",
        "        x = self.fc_2(x)\n",
        "        x = self.ac_2(x)\n",
        "        x = self.bn_2(x)\n",
        "        x = self.do_2(x)\n",
        "        x = self.fc_3(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "v4OSUwhxhxBY"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_val(model, optimizer, epochs):\n",
        "    criterion = nn.MSELoss()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        for i, data_train in enumerate(train_loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            pred_train = model(data_train[0].float())\n",
        "            loss_train = criterion(pred_train, data_train[1].float())\n",
        "            loss_train.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i % 50 == 0:\n",
        "                model.eval()\n",
        "                \n",
        "                for _, data_test in enumerate(test_loader):\n",
        "                    pred_test = model(data_test[0].float())\n",
        "                    loss_test = criterion(pred_test, data_test[1].float())\n",
        "                \n",
        "                model.train()            \n",
        "            \n",
        "                print(\n",
        "                    f'Epoch {epoch + 1}/{epochs}\\t\\t' \\\n",
        "                    f'train loss {round(loss_train.item(), 2)}\\t\\t' \\\n",
        "                    f'test loss {round(loss_test.item(), 2)}.'\n",
        "                )\n",
        "\n",
        "    print('Training is finished!')"
      ],
      "metadata": {
        "id": "XE6alr1tmIXB"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sgd = FeedForward(x.shape[1])\n",
        "optimizer_sgd = SGD(model_sgd.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "X6J5oMnnpBBD"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "data_val(model_sgd, optimizer_sgd, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8goIHKAz9m_m",
        "outputId": "28e04a71-8d66-425b-bdc7-647359a42e8f"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\t\ttrain loss 7.13\t\ttest loss 3.49.\n",
            "Epoch 1/10\t\ttrain loss 5.74\t\ttest loss 4.26.\n",
            "Epoch 1/10\t\ttrain loss 4.74\t\ttest loss 3.48.\n",
            "Epoch 1/10\t\ttrain loss 4.75\t\ttest loss 2.89.\n",
            "Epoch 2/10\t\ttrain loss 4.23\t\ttest loss 2.73.\n",
            "Epoch 2/10\t\ttrain loss 2.95\t\ttest loss 2.35.\n",
            "Epoch 2/10\t\ttrain loss 3.36\t\ttest loss 1.94.\n",
            "Epoch 2/10\t\ttrain loss 2.62\t\ttest loss 1.71.\n",
            "Epoch 3/10\t\ttrain loss 2.8\t\ttest loss 1.62.\n",
            "Epoch 3/10\t\ttrain loss 2.44\t\ttest loss 1.52.\n",
            "Epoch 3/10\t\ttrain loss 2.27\t\ttest loss 1.39.\n",
            "Epoch 3/10\t\ttrain loss 2.76\t\ttest loss 1.32.\n",
            "Epoch 4/10\t\ttrain loss 1.72\t\ttest loss 1.31.\n",
            "Epoch 4/10\t\ttrain loss 1.66\t\ttest loss 1.25.\n",
            "Epoch 4/10\t\ttrain loss 1.32\t\ttest loss 1.2.\n",
            "Epoch 4/10\t\ttrain loss 1.72\t\ttest loss 1.18.\n",
            "Epoch 5/10\t\ttrain loss 1.32\t\ttest loss 1.17.\n",
            "Epoch 5/10\t\ttrain loss 1.81\t\ttest loss 1.16.\n",
            "Epoch 5/10\t\ttrain loss 1.31\t\ttest loss 1.16.\n",
            "Epoch 5/10\t\ttrain loss 1.33\t\ttest loss 1.16.\n",
            "Epoch 6/10\t\ttrain loss 1.81\t\ttest loss 1.16.\n",
            "Epoch 6/10\t\ttrain loss 1.59\t\ttest loss 1.16.\n",
            "Epoch 6/10\t\ttrain loss 1.4\t\ttest loss 1.16.\n",
            "Epoch 6/10\t\ttrain loss 1.6\t\ttest loss 1.17.\n",
            "Epoch 7/10\t\ttrain loss 1.32\t\ttest loss 1.16.\n",
            "Epoch 7/10\t\ttrain loss 1.59\t\ttest loss 1.17.\n",
            "Epoch 7/10\t\ttrain loss 1.49\t\ttest loss 1.18.\n",
            "Epoch 7/10\t\ttrain loss 1.73\t\ttest loss 1.18.\n",
            "Epoch 8/10\t\ttrain loss 1.82\t\ttest loss 1.18.\n",
            "Epoch 8/10\t\ttrain loss 1.47\t\ttest loss 1.18.\n",
            "Epoch 8/10\t\ttrain loss 1.61\t\ttest loss 1.18.\n",
            "Epoch 8/10\t\ttrain loss 1.28\t\ttest loss 1.18.\n",
            "Epoch 9/10\t\ttrain loss 1.44\t\ttest loss 1.19.\n",
            "Epoch 9/10\t\ttrain loss 1.52\t\ttest loss 1.19.\n",
            "Epoch 9/10\t\ttrain loss 1.53\t\ttest loss 1.19.\n",
            "Epoch 9/10\t\ttrain loss 1.17\t\ttest loss 1.19.\n",
            "Epoch 10/10\t\ttrain loss 1.11\t\ttest loss 1.2.\n",
            "Epoch 10/10\t\ttrain loss 1.43\t\ttest loss 1.2.\n",
            "Epoch 10/10\t\ttrain loss 1.43\t\ttest loss 1.2.\n",
            "Epoch 10/10\t\ttrain loss 1.46\t\ttest loss 1.2.\n",
            "Training is finished!\n",
            "CPU times: user 2.8 s, sys: 22.3 ms, total: 2.83 s\n",
            "Wall time: 2.84 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_RMSprop = FeedForward(x.shape[1])\n",
        "optimizer_RMSprop = RMSprop(model_RMSprop.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "mY-1-YkXpWP5"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "data_val(model_RMSprop, optimizer_RMSprop, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrlgBIlD9fMH",
        "outputId": "70b07634-3324-4a03-8037-8ba3b0136bcb"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\t\ttrain loss 7.34\t\ttest loss 1.85.\n",
            "Epoch 1/10\t\ttrain loss 4.53\t\ttest loss 2.81.\n",
            "Epoch 1/10\t\ttrain loss 2.92\t\ttest loss 1.85.\n",
            "Epoch 1/10\t\ttrain loss 2.17\t\ttest loss 1.34.\n",
            "Epoch 2/10\t\ttrain loss 2.5\t\ttest loss 1.29.\n",
            "Epoch 2/10\t\ttrain loss 2.1\t\ttest loss 1.16.\n",
            "Epoch 2/10\t\ttrain loss 2.05\t\ttest loss 1.18.\n",
            "Epoch 2/10\t\ttrain loss 1.68\t\ttest loss 1.2.\n",
            "Epoch 3/10\t\ttrain loss 1.71\t\ttest loss 1.18.\n",
            "Epoch 3/10\t\ttrain loss 1.71\t\ttest loss 1.2.\n",
            "Epoch 3/10\t\ttrain loss 1.71\t\ttest loss 1.21.\n",
            "Epoch 3/10\t\ttrain loss 1.82\t\ttest loss 1.21.\n",
            "Epoch 4/10\t\ttrain loss 1.79\t\ttest loss 1.2.\n",
            "Epoch 4/10\t\ttrain loss 1.82\t\ttest loss 1.22.\n",
            "Epoch 4/10\t\ttrain loss 1.56\t\ttest loss 1.22.\n",
            "Epoch 4/10\t\ttrain loss 1.23\t\ttest loss 1.22.\n",
            "Epoch 5/10\t\ttrain loss 1.68\t\ttest loss 1.23.\n",
            "Epoch 5/10\t\ttrain loss 1.32\t\ttest loss 1.22.\n",
            "Epoch 5/10\t\ttrain loss 1.47\t\ttest loss 1.23.\n",
            "Epoch 5/10\t\ttrain loss 1.75\t\ttest loss 1.24.\n",
            "Epoch 6/10\t\ttrain loss 1.75\t\ttest loss 1.23.\n",
            "Epoch 6/10\t\ttrain loss 1.49\t\ttest loss 1.24.\n",
            "Epoch 6/10\t\ttrain loss 1.6\t\ttest loss 1.24.\n",
            "Epoch 6/10\t\ttrain loss 1.17\t\ttest loss 1.22.\n",
            "Epoch 7/10\t\ttrain loss 1.38\t\ttest loss 1.23.\n",
            "Epoch 7/10\t\ttrain loss 1.51\t\ttest loss 1.23.\n",
            "Epoch 7/10\t\ttrain loss 1.61\t\ttest loss 1.22.\n",
            "Epoch 7/10\t\ttrain loss 1.41\t\ttest loss 1.25.\n",
            "Epoch 8/10\t\ttrain loss 1.45\t\ttest loss 1.23.\n",
            "Epoch 8/10\t\ttrain loss 1.47\t\ttest loss 1.23.\n",
            "Epoch 8/10\t\ttrain loss 1.53\t\ttest loss 1.25.\n",
            "Epoch 8/10\t\ttrain loss 1.35\t\ttest loss 1.22.\n",
            "Epoch 9/10\t\ttrain loss 1.52\t\ttest loss 1.25.\n",
            "Epoch 9/10\t\ttrain loss 1.15\t\ttest loss 1.24.\n",
            "Epoch 9/10\t\ttrain loss 1.64\t\ttest loss 1.27.\n",
            "Epoch 9/10\t\ttrain loss 1.44\t\ttest loss 1.28.\n",
            "Epoch 10/10\t\ttrain loss 1.28\t\ttest loss 1.3.\n",
            "Epoch 10/10\t\ttrain loss 1.56\t\ttest loss 1.25.\n",
            "Epoch 10/10\t\ttrain loss 1.49\t\ttest loss 1.25.\n",
            "Epoch 10/10\t\ttrain loss 1.1\t\ttest loss 1.23.\n",
            "Training is finished!\n",
            "CPU times: user 3.22 s, sys: 27.5 ms, total: 3.25 s\n",
            "Wall time: 3.25 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_Adam = FeedForward(x.shape[1])\n",
        "optimizer_Adam = Adam(model_Adam.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "2cdV5mMS7XZu"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "data_val(model_Adam, optimizer_Adam, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNw3CcZT9XqQ",
        "outputId": "06cb5280-b9d5-432d-edd7-50490d0b701f"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\t\ttrain loss 7.7\t\ttest loss 3.48.\n",
            "Epoch 1/10\t\ttrain loss 6.63\t\ttest loss 4.65.\n",
            "Epoch 1/10\t\ttrain loss 4.56\t\ttest loss 3.88.\n",
            "Epoch 1/10\t\ttrain loss 3.94\t\ttest loss 3.17.\n",
            "Epoch 2/10\t\ttrain loss 4.93\t\ttest loss 2.88.\n",
            "Epoch 2/10\t\ttrain loss 3.67\t\ttest loss 2.06.\n",
            "Epoch 2/10\t\ttrain loss 2.32\t\ttest loss 1.51.\n",
            "Epoch 2/10\t\ttrain loss 1.82\t\ttest loss 1.24.\n",
            "Epoch 3/10\t\ttrain loss 1.51\t\ttest loss 1.22.\n",
            "Epoch 3/10\t\ttrain loss 2.42\t\ttest loss 1.16.\n",
            "Epoch 3/10\t\ttrain loss 1.76\t\ttest loss 1.18.\n",
            "Epoch 3/10\t\ttrain loss 2.11\t\ttest loss 1.18.\n",
            "Epoch 4/10\t\ttrain loss 1.48\t\ttest loss 1.17.\n",
            "Epoch 4/10\t\ttrain loss 1.29\t\ttest loss 1.21.\n",
            "Epoch 4/10\t\ttrain loss 1.78\t\ttest loss 1.19.\n",
            "Epoch 4/10\t\ttrain loss 1.57\t\ttest loss 1.19.\n",
            "Epoch 5/10\t\ttrain loss 1.34\t\ttest loss 1.2.\n",
            "Epoch 5/10\t\ttrain loss 1.31\t\ttest loss 1.22.\n",
            "Epoch 5/10\t\ttrain loss 1.57\t\ttest loss 1.21.\n",
            "Epoch 5/10\t\ttrain loss 1.57\t\ttest loss 1.21.\n",
            "Epoch 6/10\t\ttrain loss 1.94\t\ttest loss 1.21.\n",
            "Epoch 6/10\t\ttrain loss 1.52\t\ttest loss 1.23.\n",
            "Epoch 6/10\t\ttrain loss 1.74\t\ttest loss 1.22.\n",
            "Epoch 6/10\t\ttrain loss 1.55\t\ttest loss 1.22.\n",
            "Epoch 7/10\t\ttrain loss 1.12\t\ttest loss 1.22.\n",
            "Epoch 7/10\t\ttrain loss 1.66\t\ttest loss 1.21.\n",
            "Epoch 7/10\t\ttrain loss 1.45\t\ttest loss 1.22.\n",
            "Epoch 7/10\t\ttrain loss 1.75\t\ttest loss 1.22.\n",
            "Epoch 8/10\t\ttrain loss 1.58\t\ttest loss 1.22.\n",
            "Epoch 8/10\t\ttrain loss 1.85\t\ttest loss 1.22.\n",
            "Epoch 8/10\t\ttrain loss 1.45\t\ttest loss 1.22.\n",
            "Epoch 8/10\t\ttrain loss 1.71\t\ttest loss 1.22.\n",
            "Epoch 9/10\t\ttrain loss 1.66\t\ttest loss 1.22.\n",
            "Epoch 9/10\t\ttrain loss 1.53\t\ttest loss 1.22.\n",
            "Epoch 9/10\t\ttrain loss 1.86\t\ttest loss 1.23.\n",
            "Epoch 9/10\t\ttrain loss 1.64\t\ttest loss 1.23.\n",
            "Epoch 10/10\t\ttrain loss 1.6\t\ttest loss 1.24.\n",
            "Epoch 10/10\t\ttrain loss 1.51\t\ttest loss 1.23.\n",
            "Epoch 10/10\t\ttrain loss 1.52\t\ttest loss 1.23.\n",
            "Epoch 10/10\t\ttrain loss 1.35\t\ttest loss 1.24.\n",
            "Training is finished!\n",
            "CPU times: user 3.76 s, sys: 40.5 ms, total: 3.8 s\n",
            "Wall time: 3.82 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод: все алгоритмы оптимизации хорошо отработали, но наша задача довольна простая для обучения. \n",
        "Поэтому стохастический градиентный спуск справился не хуже чем остальные оптимизаторы, но затратил на порядок меньше времени."
      ],
      "metadata": {
        "id": "lt7aZb9q-CDE"
      }
    }
  ]
}