{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VVdovichev/PyTorch_GB/blob/main/HW_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ9ycJpFVQbK"
      },
      "source": [
        "1.   Обучите CNN (самописная) на CIFAR-100.\n",
        "2.   Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50.\n",
        "3.   *Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50 с аугментацией данных.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs-AydJ_VK84"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BVHJKicVtVF"
      },
      "source": [
        "1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLg4NODQVr7S",
        "outputId": "f4a45cb2-63cb-4da2-dda8-544333fe8f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "dataset = datasets.CIFAR100(root='data/', train=True, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XRy450CVzGf"
      },
      "outputs": [],
      "source": [
        "class MyOwnCifar(torch.utils.data.Dataset):\n",
        "   \n",
        "    def __init__(self, init_dataset, transform=None):\n",
        "        self._base_dataset = init_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self._base_dataset[idx][0]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, self._base_dataset[idx][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYFQCjoLV4tn"
      },
      "outputs": [],
      "source": [
        "trans_actions = transforms.Compose([transforms.Resize(44),\n",
        "                                    transforms.RandomCrop(32, padding=4), \n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "\n",
        "def train_valid_split(Xt):\n",
        "    X_train, X_test = train_test_split(Xt, test_size=0.05, random_state=13)\n",
        "    return X_train, X_test\n",
        "\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAvhBAupV-Fd"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=False,\n",
        "                          num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSeflOe8WB1x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "I67jxVOuWEOX",
        "outputId": "174daac5-df33-4e4e-88e0-9579b72f2624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "for img, lbl in train_loader:\n",
        "    print(img.shape)\n",
        "    print(dataset.classes)\n",
        "    plt.imshow(img[0].permute(1, 2, 0))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vrpvrNCkzU5R",
        "outputId": "c8db7a25-1bec-479c-a849-baef1760ebcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEbqcco-W67x",
        "outputId": "b424af77-18d1-4b88-ed0d-335f5fa52855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (dp_one): Dropout(p=0.2, inplace=False)\n",
            "  (dp_two): Dropout(p=0.2, inplace=False)\n",
            "  (bn_one): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_one): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn_two): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_two): Conv2d(30, 60, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn_three): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_three): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn_four): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=480, out_features=200, bias=True)\n",
            "  (out): Linear(in_features=200, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.dp_one = nn.Dropout(0.2)\n",
        "        self.dp_two = nn.Dropout(0.2)\n",
        "        \n",
        "        self.bn_one = torch.nn.BatchNorm2d(3) \n",
        "        self.conv_one = torch.nn.Conv2d(3, 30, 3)\n",
        "        self.bn_two = torch.nn.BatchNorm2d(30) \n",
        "        self.conv_two = torch.nn.Conv2d(30, 60, 3)\n",
        "        self.bn_three = torch.nn.BatchNorm2d(60)\n",
        "        self.conv_three = torch.nn.Conv2d(60, 120, 3)\n",
        "        self.bn_four = torch.nn.BatchNorm2d(120)\n",
        "        self.fc1 = torch.nn.Linear(480, 200)\n",
        "        #self.fc2 = torch.nn.Linear(200, 60)\n",
        "        self.out = torch.nn.Linear(200, 100)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.bn_one(x)\n",
        "        x = self.conv_one(x)\n",
        "        x = F.leaky_relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn_two(x)\n",
        "        x = self.conv_two(x)\n",
        "        x = F.leaky_relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn_three(x)\n",
        "        x = self.conv_three(x)\n",
        "        x = F.leaky_relu(x, 0.1)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn_four(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dp_one(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dp_two(x)\n",
        "        #x = self.fc2(x)\n",
        "        #x = F.relu(x)\n",
        "        return self.out(x)\n",
        "       \n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_EbvJ5wbWeK"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZEdBj6Bbd5F",
        "outputId": "73bd3e64-929e-48a0-8253-d10b97b8a0ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "       BatchNorm2d-1            [-1, 3, 32, 32]               6\n",
            "            Conv2d-2           [-1, 30, 30, 30]             840\n",
            "       BatchNorm2d-3           [-1, 30, 15, 15]              60\n",
            "            Conv2d-4           [-1, 60, 13, 13]          16,260\n",
            "       BatchNorm2d-5             [-1, 60, 6, 6]             120\n",
            "            Conv2d-6            [-1, 120, 4, 4]          64,920\n",
            "       BatchNorm2d-7            [-1, 120, 2, 2]             240\n",
            "           Dropout-8                  [-1, 480]               0\n",
            "            Linear-9                  [-1, 200]          96,200\n",
            "          Dropout-10                  [-1, 200]               0\n",
            "           Linear-11                  [-1, 100]          20,100\n",
            "================================================================\n",
            "Total params: 198,746\n",
            "Trainable params: 198,746\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.40\n",
            "Params size (MB): 0.76\n",
            "Estimated Total Size (MB): 1.17\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(net, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BPXdixTbhui",
        "outputId": "fa0ff5a3-5234-430f-9723-5f212fa977de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/372]. Loss: 0.036. Acc: 0.023. Test acc: 0.013\n",
            "Epoch [1/5]. Step [301/372]. Loss: 0.033. Acc: 0.062. Test acc: 0.089\n",
            "Epoch [2/5]. Step [1/372]. Loss: 0.031. Acc: 0.102. Test acc: 0.116\n",
            "Epoch [2/5]. Step [301/372]. Loss: 0.030. Acc: 0.104. Test acc: 0.131\n",
            "Epoch [3/5]. Step [1/372]. Loss: 0.028. Acc: 0.133. Test acc: 0.132\n",
            "Epoch [3/5]. Step [301/372]. Loss: 0.029. Acc: 0.129. Test acc: 0.160\n",
            "Epoch [4/5]. Step [1/372]. Loss: 0.028. Acc: 0.156. Test acc: 0.156\n",
            "Epoch [4/5]. Step [301/372]. Loss: 0.028. Acc: 0.143. Test acc: 0.179\n",
            "Epoch [5/5]. Step [1/372]. Loss: 0.027. Acc: 0.180. Test acc: 0.167\n",
            "Epoch [5/5]. Step [301/372]. Loss: 0.028. Acc: 0.160. Test acc: 0.197\n",
            "Training is finished!\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "net.train()\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            net.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "            test_running_right, test_running_total = 0.0, 0.0\n",
        "            for i, data in enumerate(valid_loader):\n",
        "            \n",
        "                test_outputs = net(data[0])\n",
        "                test_running_total += len(data[1])\n",
        "                test_running_right += (data[1] == torch.max(test_outputs, 1)[1]).sum()\n",
        "            \n",
        "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "        \n",
        "        net.train()\n",
        "        \n",
        "print('Training is finished!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sbi-FkQ5oIpl",
        "outputId": "ab0f2371-a6b6-420b-e207-5d7ab9aee04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "resnet50 = models.resnet50(pretrained=True)\n",
        "print(resnet50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqIyQi1nqKCC",
        "outputId": "253a0f18-a22d-462b-bb6d-9dae2b6da09c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                 [-1, 1000]       2,049,000\n",
            "================================================================\n",
            "Total params: 25,557,032\n",
            "Trainable params: 25,557,032\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 286.56\n",
            "Params size (MB): 97.49\n",
            "Estimated Total Size (MB): 384.62\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary((resnet50), input_size=(3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp_f3zZvqQLy"
      },
      "outputs": [],
      "source": [
        "for param in list(resnet50.parameters())[:]:\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COEL34DVqZyu",
        "outputId": "4f3573c9-3b18-42e8-9be0-2ea8b8aeec50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
            "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
            "             ReLU-15            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
            "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
            "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
            "             ReLU-19             [-1, 64, 8, 8]               0\n",
            "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
            "             ReLU-22             [-1, 64, 8, 8]               0\n",
            "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
            "             ReLU-25            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
            "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
            "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
            "             ReLU-29             [-1, 64, 8, 8]               0\n",
            "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
            "             ReLU-32             [-1, 64, 8, 8]               0\n",
            "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
            "             ReLU-35            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
            "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
            "             ReLU-39            [-1, 128, 8, 8]               0\n",
            "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
            "             ReLU-42            [-1, 128, 4, 4]               0\n",
            "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-47            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
            "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
            "             ReLU-51            [-1, 128, 4, 4]               0\n",
            "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
            "             ReLU-54            [-1, 128, 4, 4]               0\n",
            "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-57            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
            "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
            "             ReLU-61            [-1, 128, 4, 4]               0\n",
            "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
            "             ReLU-64            [-1, 128, 4, 4]               0\n",
            "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-67            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
            "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
            "             ReLU-71            [-1, 128, 4, 4]               0\n",
            "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
            "             ReLU-74            [-1, 128, 4, 4]               0\n",
            "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-77            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
            "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
            "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
            "             ReLU-81            [-1, 256, 4, 4]               0\n",
            "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
            "             ReLU-84            [-1, 256, 2, 2]               0\n",
            "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
            "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
            "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-89           [-1, 1024, 2, 2]               0\n",
            "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
            "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
            "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
            "             ReLU-93            [-1, 256, 2, 2]               0\n",
            "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
            "             ReLU-96            [-1, 256, 2, 2]               0\n",
            "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-99           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
            "            ReLU-103            [-1, 256, 2, 2]               0\n",
            "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
            "            ReLU-106            [-1, 256, 2, 2]               0\n",
            "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-109           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
            "            ReLU-113            [-1, 256, 2, 2]               0\n",
            "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
            "            ReLU-116            [-1, 256, 2, 2]               0\n",
            "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-119           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
            "            ReLU-123            [-1, 256, 2, 2]               0\n",
            "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
            "            ReLU-126            [-1, 256, 2, 2]               0\n",
            "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-129           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
            "            ReLU-133            [-1, 256, 2, 2]               0\n",
            "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
            "            ReLU-136            [-1, 256, 2, 2]               0\n",
            "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-139           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-143            [-1, 512, 2, 2]               0\n",
            "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-146            [-1, 512, 1, 1]               0\n",
            "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
            "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-151           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-155            [-1, 512, 1, 1]               0\n",
            "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-158            [-1, 512, 1, 1]               0\n",
            "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-161           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-165            [-1, 512, 1, 1]               0\n",
            "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-168            [-1, 512, 1, 1]               0\n",
            "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-171           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                  [-1, 100]         204,900\n",
            "================================================================\n",
            "Total params: 23,712,932\n",
            "Trainable params: 204,900\n",
            "Non-trainable params: 23,508,032\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.86\n",
            "Params size (MB): 90.46\n",
            "Estimated Total Size (MB): 96.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "resnet50.fc = nn.Linear(2048, 100)\n",
        "\n",
        "summary(resnet50, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s_-oFs2qj2j"
      },
      "outputs": [],
      "source": [
        "train_actions = transforms.Compose([transforms.Resize(256),\n",
        "                                    transforms.RandomCrop(224, padding=4), \n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                         std=[0.229, 0.224, 0.225])])\n",
        "valid_transforms = transforms.Compose([transforms.Resize(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                            std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, train_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, valid_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4pg5GaUq35k"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=False,\n",
        "                                           num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqCYmw2Yq7Bc"
      },
      "outputs": [],
      "source": [
        "params_to_update = []\n",
        "for name, param in resnet50.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-fHIn4aq-JT",
        "outputId": "e47216d9-c7eb-4d6f-e57b-760f5e122ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/372]. Loss: 0.036. Acc: 0.008. Test acc: 0.010\n",
            "Epoch [1/5]. Step [301/372]. Loss: 0.020. Acc: 0.399. Test acc: 0.507\n",
            "Epoch [2/5]. Step [1/372]. Loss: 0.014. Acc: 0.508. Test acc: 0.508\n",
            "Epoch [2/5]. Step [301/372]. Loss: 0.013. Acc: 0.536. "
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "resnet50.train()\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet50(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            resnet50.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "            test_running_right, test_running_total = 0.0, 0.0\n",
        "            for i, data in enumerate(valid_loader):\n",
        "            \n",
        "                test_outputs = resnet50(data[0])\n",
        "                test_running_total += len(data[1])\n",
        "                test_running_right += (data[1] == torch.max(test_outputs, 1)[1]).sum()\n",
        "            \n",
        "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "                                                                                                                                             \n",
        "        resnet50.train()\n",
        "        \n",
        "print('Training is finished!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laoFLhFIrRXq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgjNKosc+f+p10FIJv70SU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}